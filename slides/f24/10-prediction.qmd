---
title: "Prediction"
subtitle: "POL51"
format: 
  clean-revealjs:
    incremental: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Juan Tellez
    email: jftellez@ucdavis.edu
    affiliations: UC Davis
date: last-modified
title-slide-attributes:
  data-background-image: ../img/dubois-spiral-2.png
  data-background-size: contain
  data-background-position: right
---


```{r setup, include=FALSE}
# set knit options
knitr::opts_chunk$set(
  fig.width=9, 
  fig.height=5, 
  fig.retina=3,
  fig.align="center",
  tidy = FALSE,
  tidy.opts = list(width.cutoff = 80),
  out.width = "100%",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE
)


# source
source(here::here("R/funcs.R"))

# libraries
library(juanr)
library(socviz)
library(gapminder)
library(broom)

```




# Plan for today {.center background-color="`r full`"}


. . .


Making predictions

. . .


Multiple regression


. . .


How right are we?



# Why predict?


## Why predict?


::: columns
::: {.column width="50%"}
- Companies, policymakers, and academics want to predict
- who will win an election
- whether UN peacekeepers can reduce conflict
- whether you'll get the vaccine or not
- At stake is what decision to take under **uncertainty about the future**
:::

::: {.column width="50%"}
```{r}
knitr::include_graphics(here::here("slides/img/prediction.png"))
```

:::
:::


## Making predictions


::: columns
::: {.column width="50%"}
The basics of prediction are pretty straightforward:

1. Take/collect existing data âœ…
2. Fit a model to it âœ…
3. Design a **scenario** you want a prediction for â˜‘ï¸
4. Use the model to generate an **estimate** for that scenario â˜‘ï¸
:::

::: {.column width="50%"}
```{r}
knitr::include_graphics(here::here("slides/img/tea-reading.jpeg"))
```
:::
:::


## What's the scenario?

::: columns
::: {.column width="60%"}
- A scenario is a hypothetical **observation** (real, or imagined) that we want a prediction for
- You define a scenario by picking **values** for explanatory variables
- Example: what is the predicted fuel efficiency for a car that *weighs 3.25 tons*?
:::

::: {.column width="40%"}
```{r}
knitr::include_graphics(here::here("slides/img/scenario.jpeg"))
```
:::
:::


## Prediction (by hand)

```{r, echo = TRUE}
weight_model = lm(mpg ~ wt, data = mtcars)
```

Remeber our model is an equation: 

. . .

$\widehat{mpg} = 37.29 - 5.34(wt)$

. . .


**Scenario**: a car that weights 3.25 tons $\rightarrow$ what fuel efficiency should we expect?


. . .


To get an estimate of `mpg`, we simply plug in the value of "weight" we are interested in:

. . .


$\widehat{mpg} = 37.29 - 5.34 \times \color{red}{3.25} = 19.935$



## Prediction (in R)

First **define the scenario** we want a prediction for, using `crossing()`

. . .

```{r, echo = TRUE}
weight_scenario = crossing(wt = 3.25) 
weight_scenario
```

. . .

Note that I store this as a data object

. . . 

::: {.callout-note}
the variables in `crossing` have to have the same name as the variables in the model
:::





## Prediction (in R)

We can then combine our scenario with our model using `augment()`

```{r, echo = TRUE}
augment(weight_model, newdata = weight_scenario)
```

. . .

`augment` plugs in scenario to our model to get an estimate

. . .


Note we got the same answer as when we did it by hand


::: {.callout-note}
We tell `augment` what our new scenario is using the `newdata = ` argument
:::



## Multiple scenarios

We can also look at multiple scenarios: a light, medium, and heavy car:


. . .


```{r, echo = TRUE}
weight_scenario = crossing(wt = c(1.5, 3, 5)) 
weight_scenario
```

. . .


And then use `augment` to get the estimates:


```{r, echo = TRUE}
augment(weight_model, newdata = weight_scenario)
```





## Sequence of scenarios

Or we can look at a *sequence* of scenarios using the `seq()` function

. . .


Example: every weight between 2 and 6 tons, in .1 ton increments


. . .



```{r, echo = TRUE}
seq_weights = crossing(wt = seq(from = 2, to = 6, by = .1)) 
seq_weights
```



::: {.callout-note}
`seq` needs a starting point (`from`), an end point (`to`), and an interval (`by`)
:::




## Prediction (in R)


And then get predictions for all these scenarios:


```{r, echo = TRUE}
weight_preds = augment(weight_model, newdata = seq_weights)
weight_preds
```






## Trivial

Do we really need a model to predict MPG when weight = 3.25? Probably not

```{r}
ggplot(mtcars, aes(x = wt, y = mpg)) + 
  geom_point() + geom_smooth(method = "lm") + 
  theme_nice()
```





## Multiple regression

The real power of modeling and prediction comes with using multiple explanatory variables

. . .

Many factors influence a car's fuel efficiency; we can use that information to make more precise predictions

. . .


```{r}
mtcars %>% 
  select(mpg, wt, cyl, hp, am, vs) |> 
  sample_n(4) |> 
  kbl(digits = 2)
```




## Multiple regression

Here, a car's fuel efficiency is a function of its weight (`wt`), number of cylinders (`cyl`), horse power (`hp`), and whether its transmission is manual or automatic (`am`)

```{r, echo = TRUE}
big_model = lm(mpg ~ wt + cyl + hp + am, data = mtcars)
```

. . .

The model equation we want in the end is this one: 

$$\operatorname{mpg} = \beta_0 + \color{red}{\beta_{1}}(\operatorname{wt}) + \color{red}{\beta_{2}}(\operatorname{cyl}) + \color{red}{\beta_{3}}(\operatorname{hp}) + \color{red}{\beta_{4}}(\operatorname{am})$$




# Multiple regression {.center background-color="`r full`"}



## Multiple regression


::: columns
::: {.column width="50%"}
* Just as when we had one variable, our OLS model is trying to find the values of  $\beta$ that "best" fits the data

* OLS estimator = $\sum{(Y_i - \hat{Y_i})^2}$


* Where $\widehat{Y} = \beta_0 + \beta_1 x_1 + . . . \beta_4 x_4$


* Now searching for $\beta_0 ... \beta_4$ to minimize loss function
:::

::: {.column width="50%"}
```{r}
knitr::include_graphics(here::here("slides/img/spin-plates.jpeg"))
```
*`lm()` hard at work*
:::
:::







## Interpretation


::: columns
::: {.column width="50%"}
```{r, echo = FALSE}
tidy(big_model) %>% 
  select(term, estimate) |> 
  kbl(digits = 2)
```
:::

::: {.column width="50%"}
* wt = every ton of weight is associated with a 2.61 decrease in mpg
* cyl = every cylinder is associated with a .7 decrease in mpg
* hp = every unit of horse power is associated with a .02 decrease in mpg
* am = on average, cars with manual transmissions (`am = 1`) have 1.48 more mpg than cars with automatic transmissions (`am = 0`)

:::
:::


::: {.notes}
notice the quantities change once we add more vars
:::






## Prediction (by hand)

We can make predictions just as before, plugging in values for our explanatory variables

$$
\operatorname{\widehat{mpg}} = 36.15 - 2.61(\operatorname{wt}) - 0.75(\operatorname{cyl}) - 0.02(\operatorname{hp}) + 1.48(\operatorname{am})
$$

. . .


With more variables, we can create more specific **scenarios**


. . .


For example: a car that weighs 3 tons, has 4 cylinders, 120 horsepower, and has a manual transmission

. . .

$$
\operatorname{\widehat{mpg}} = 36.15 - 2.61 \times \color{blue}{3} - 0.75 \times  \color{blue}{4} - 0.02 \times  \color{blue}{120} + 1.48 \times  \color{blue}{1}
$$

. . .


$$
\operatorname{\widehat{mpg}} = 24
$$


## Prediction (in R)

We can do this in R with `crossing()` and `augment()`

. . .

```{r, echo = TRUE}
big_scenario = crossing(wt = 3, cyl = 4, hp = 120, am = 1)

augment(big_model, newdata = big_scenario)
```


## Troubleshooting


Note that your scenario needs to include every variable in your model, otherwise you will get an error

. . .

The one below is missing cylinders, which is in `big_model`, and won't run:

. . .

```{r, echo = TRUE, eval = FALSE}
bad_scenario = crossing(wt = 3, hp = 120, am = 1)

augment(big_model, newdata = bad_scenario)
```




## Pick scenarios that make sense

. . .

Note that to make predictions that make sense, we have to look through our data and see what values are plausible for the variables

. . .

For example, a scenario where we set `am` = 3 doesn't make sense, since `am` is a dummy variable that takes two values (0 = automatic, 1 = manual)

. . .

But R doesn't know that, and will give you (nonsensical) estimates:

```{r, echo = TRUE}
crazy_car = crossing(wt = 3, cyl = 4, hp = 120, am = 3)
augment(big_model, newdata = crazy_car)
```

::: {.callout-note}
Remember `data |> distinct(variable)` to see a variable's values
:::



## Holding all else constant


One cool part of **multiple regression** is that we can see what happens to our estimates when one variable changes but the others are held at a fixed value

. . .

*Holding all else in the model constant*, how does increasing a car's horsepower change its fuel efficiency?


## Holding all else constant


We can use `seq()` to see what happens when horsepower changes while everything else is left at a fixed value

. . .

```{r, echo = TRUE}
varying_hp = crossing(wt = 3, cyl = 4, am = 1, hp = seq(from = 50, to = 340, by = 5))

augment(big_model, newdata = varying_hp)
```





## Visualizing predictions

We could then store our estimate, and use it for plotting

```{r, echo = TRUE, out.width="70%"}
hp_pred = augment(big_model, newdata = varying_hp)
ggplot(hp_pred, aes(x = hp, y = .fitted)) + geom_point()
```







## One more example: Gapminder

Say we wanted to predict a country's life expectancy, using population, GDP per capita, the year, and what continent it is in:

. . .

```{r, echo = TRUE}
life_model = lm(lifeExp ~ gdpPercap + pop + year + continent, data = gapminder)
tidy(life_model)
```



## Predicting health

**Scenario**: what if we wanted to predict the life expectancy of a country with a GDP per capita of $7,000, a population of 20 million, in the year 2005, in Asia?

. . .

```{r, echo = TRUE}
life_scenario = crossing(gdpPercap = 7000, pop = 20000000, year = 2005, continent = "Asia")
augment(life_model, newdata = life_scenario)
```




## Imaginary changes

What if we could "dial up" this country's GDP slowly? How would its life expectancy change? 

. . .

**Scenario**: we can vary GDP and keep all else constant

. . .


```{r, echo = TRUE}
life_scenario = crossing(gdpPercap = seq(from = 5000, to = 100000, by = 5000), 
                         pop = 20000000, year = 2005, continent = "Asia")
augment(life_model, newdata = life_scenario)
```





## Imaginary scenarios

How different would this all look in different continents? We can vary continents too:

. . .


```{r, echo = TRUE}
life_continent_scenario = crossing(gdpPercap = seq(from = 5000, to = 100000, by = 5000), 
                       pop = 20000000, year = 2005, 
                       continent = c("Asia", "Africa", "Americas", "Europe")) 
augment(life_model, newdata = life_continent_scenario)
```





## Predicting health

We can then save our predictions as an object, and plot them: 


```{r, echo = TRUE, out.width="70%"}
pred_health = augment(life_model, newdata = life_continent_scenario)
ggplot(pred_health, aes(x = gdpPercap, y = .fitted, color = continent)) + 
  geom_point() + geom_line()
```



## Your turn: ðŸ§‘â€ðŸŽ¨ Art ðŸ§‘â€ðŸŽ¨

Let's look at `art` from `{juanr}`: a dataset of auction sales records, including artistsâ€™ attributes, and market information

```{r}
art %>% 
 head() |> 
  select(artist_name, lot_title, event_year, nationality, real_price_usd) |> 
  knitr::kable(caption = "Sample from {art}.")
```


## Your turn: ðŸ§‘â€ðŸŽ¨ Art ðŸ§‘â€ðŸŽ¨

Using `art`:

1. Fit a model that predicts the sale price of the artwork (`real_price_usd`) using the year the artwork was created, the genre, the size, whether the artist is male or female, and whether the artist whent to an elite art school.

2. How much should we expect a painting to sell for if it was created in 2000, is a sculpture, is 360 inches, painted by a male artist who went to an elite art school?

3. Hold everything else constant and vary the art piece size from the smallest to the largest in the dataset. Visualize the price change.


```{r}
#| echo: false
  countdown::countdown(minutes = 10L)
```



# How right are we? {.center background-color="`r full`"}



## Prediction accuracy


::: columns
::: {.column width="50%"}
* The question with prediction is always: how accurate were we?
* If our model is predicting the outcome accurately that might be:
    * a good sign that we are modeling the process that generates the outcome well 
    * useful for forcasting the future, or situations we don't know about
:::

::: {.column width="50%"}
```{r}
knitr::include_graphics(here::here("slides/img/medieval-archer.jpeg"))
```
:::
:::




## Comparing to reality

How good are our model's predictions?

. . .

We could compare our estimate of life expectancy to a real country, say Jamaica in 2007:

. . .

```{r}
gapminder %>% 
  filter(country == "Jamaica", year == 2007) %>% 
  knitr::kable()
```

. . .

We can use Jamaica's values as our scenario, and see what our model predicted:

```{r, echo = TRUE}
jamaica = crossing(continent = "Americas", year = 2007, pop = 2780132, gdpPercap = 7321)
```



## Pretty close



Actual:

```{r}
gapminder %>% 
  filter(country == "Jamaica", year == 2007) %>% 
  knitr::kable()
```

Estimate:

```{r, echo = TRUE}
augment(life_model, newdata = jamaica)
```



## Is this really a prediction?


::: columns
::: {.column width="50%"}
- Our estimate of Jamaica is not *really* prediction, since we *used* that observation to fit our model


- This is an **in-sample** prediction $\rightarrow$ seeing how well our model does at predicting the data that we used to generate it


- "True" prediction is **out-of-sample** $\rightarrow$ using a model to generate predictions about something that *hasn't happened yet*
:::

::: {.column width="50%"}
```{r,fig.cap="Figure. Is catch and release really fishing?"}
knitr::include_graphics(here::here("slides/img/fishing.jpeg"))
```
:::
:::








## Out of sample prediction


Imagine in the year 1957 we fit a model with the info we had available at the time:

. . .

```{r, echo = TRUE}
gap_57 = gapminder %>% filter(year <= 1957)
mod_57 = lm(lifeExp ~ gdpPercap + pop + continent + year, data = gap_57)
```

. . .


Now it's 2007, someone finds the model, and wants to know: how well could this model have predicted the future?

. . .


```{r, echo = TRUE}
jamaica = crossing(continent = "Americas", year = 2007, pop = 2780132, gdpPercap = 7321)
```


. . .


This is an **out-of-sample** prediction: our model has data before 1957, but our prediction is based off of Jamaica's characteristics in 2007



## How did we do?


Jamaica in 2007:

```{r}
gapminder %>% 
  filter(country == "Jamaica", year == 2007) %>% 
  knitr::kable(digits = 1)
```


. . .


What our first model with all the data predicted, 2007 included (**in sample**):


```{r}
augment(life_model, newdata = jamaica) |> 
  kbl(digits = 1)
```


. . .


What our 1957 model predicted for 2007 (**out of sample**):


```{r}
augment(mod_57, newdata = jamaica) |> 
  kbl(digits = 1)
```


::: {.notes}
What did our model from the 50s think Jamaica would look like in the future?
:::


## Out of sample prediction is generally worse


As a general rule, models will tend to perform **worse** out-of-sample than in-sample

. . .


This is because the model is **over-fitting** the data $\rightarrow$ tailoring the model equation too closely to the data we have

. . .

Something could **change** that our data doesn't know about, or...

. . .

Our model could over-emphasize patterns that don't generalize to new data

::: {.notes}
why would this be?
:::


## You can't time the market


```{r}
knitr::include_graphics(here::here("slides/img/hairy-chart-fed.jpg"))
```


Lesson: buy index funds, set it and forget it


## Why are we so wrong about fertility?


```{r}
knitr::include_graphics(here::here("slides/img/fertility-wrong.png"))
```



## ðŸš¨ Your turn: ðŸŽ¥ The movies ðŸŽ¥ðŸš¨


Using `movies`:


1. Fit a model that predicts gross (outcome) using genre1, duration, budget, year, imdb_score, and whether or not it's in color. 

2. Look up a movie in the dataset. How well does the model predict a movie that shares that movie's characteristics?

3. Look up a movie on IMDB that came out after the data ends (2016). How well does your model predict that movie's gross? 


```{r}
countdown::countdown(minutes = 10L)
```




